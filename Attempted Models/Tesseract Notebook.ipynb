{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I13dfVEjVZ5"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Optical Character Recognition using Tesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDZYVGrJkorH"
      },
      "source": [
        "### Step1. Install Pytesseract and tesseract-OCR in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWwpI-24_Nob",
        "outputId": "0a71153c-2192-4607-b549-8b3f0214d21b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command not found\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujL16dZ2_O-3",
        "outputId": "3e363a32-bc51-4dbd-ed1d-fe9edd594646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in c:\\users\\akshat\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\akshat\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\akshat\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (11.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67-wnx3xxCZm",
        "outputId": "3b2ef528-5c3a-48a4-fe00-bd32e671ff0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Download the cascade file if not already present\n",
        "!wget -O haarcascade_russian_plate_number.xml https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_russian_plate_number.xml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenCV version: 4.11.0\n",
            "Numpy version: 2.2.4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"Numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkdifw3EsQ8q",
        "outputId": "302d046f-c4d3-4295-c6b8-1ff9ee871bb3"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# def detect_and_crop_plate(image_path, cascade_path='haarcascade_russian_plate_number.xml'):\n",
        "#     # Load the Haar cascade classifier for license plates\n",
        "#     plate_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "#     if plate_cascade.empty():\n",
        "#         print(\"Error loading cascade file. Check the path and file name.\")\n",
        "#         return\n",
        "\n",
        "#     # Read the PNG image from the given path\n",
        "#     image = cv2.imread(image_path)\n",
        "#     if image is None:\n",
        "#         print(\"Error reading image. Check the file path.\")\n",
        "#         return\n",
        "\n",
        "#     # Convert the image to grayscale for detection\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Detect number plates in the image\n",
        "#     plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
        "\n",
        "#     if len(plates) == 0:\n",
        "#         print(\"No license plates detected.\")\n",
        "#         return\n",
        "\n",
        "#     # Process each detected plate (if multiple are found)\n",
        "#     for i, (x, y, w, h) in enumerate(plates):\n",
        "#         # Crop the detected license plate\n",
        "#         cropped_plate = image[y:y+h, x:x+w]\n",
        "\n",
        "#         # Display the cropped license plate using cv2_imshow\n",
        "#         cv2.imshow(f'Cropped Plate {i+1}', cropped_plate)\n",
        "\n",
        "#         # Save the cropped license plate\n",
        "#         cv2.imwrite('cropped_plate.png', cropped_plate)\n",
        "#         print(f'Cropped license plate saved as croppedplate.png')\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Download the cascade file if not already present\n",
        "#     # !wget -O haarcascade_russian_plate_number.xml https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_russian_plate_number.xml\n",
        "\n",
        "#     # Replace with the correct path to your uploaded PNG file\n",
        "#     image_path = 'D:/Academics/Semester VI/ES 333 - Microprocessors and Embedded Systems/PROJECT/license_plate_image.png'\n",
        "#     detect_and_crop_plate(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlsiJdwnkyx7"
      },
      "source": [
        "### Step2. import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QKJh7JjTAqzO"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "228oAJ9XvMKb",
        "outputId": "dfcd3250-bc53-4eba-f0b9-258b1e3884cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#sharpen image\n",
        "image = cv2.imread(\"D:/Academics/Semester VI/ES 333 - Microprocessors and Embedded Systems/PROJECT/license_plate_image.png\")\n",
        "sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "sharpened = cv2.filter2D(image, -1, sharpen_kernel)\n",
        "cv2.imwrite(\"sharpened.png\", sharpened)\n",
        "\n",
        "#remove noise\n",
        "gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)\n",
        "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "cv2.imwrite(\"thresh.png\", thresh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDdbltgIlF3Q"
      },
      "source": [
        "## Step4. Text Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HaM3cMUDA_Ma"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted text: Python\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "# (optional) if you haven't set the path already\n",
        "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "\n",
        "extractedInformation = pytesseract.image_to_string(Image.open('sharpened.png')).strip()\n",
        "\n",
        "# Defensive check before accessing index 2\n",
        "if len(extractedInformation) > 2 and extractedInformation[2] == 'O':\n",
        "    extractedInformation = extractedInformation[:2] + '0' + extractedInformation[3:]\n",
        "\n",
        "# Defensive check before accessing index 0\n",
        "if len(extractedInformation) > 0 and not extractedInformation[0].isalpha():\n",
        "    extractedInformation = extractedInformation[1:]\n",
        "\n",
        "print(f\"Extracted text: {extractedInformation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D552cuoflHvx"
      },
      "source": [
        "### Step5. Printing the extracted information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Key-3vILBNUd",
        "outputId": "7cff6449-c9e2-4e50-e074-096de5a78077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python\n"
          ]
        }
      ],
      "source": [
        "print(extractedInformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OCR Result: OO\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "# Load and grayscale\n",
        "img = cv2.imread(\"license_plate_image.png\")\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Enhance contrast with CLAHE\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "gray = clahe.apply(gray)\n",
        "\n",
        "# Resize to improve OCR accuracy\n",
        "resized = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# Morph close to connect thin/broken lines\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "closed = cv2.morphologyEx(resized, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# Optional: slight blur to suppress tiny noise\n",
        "blurred = cv2.GaussianBlur(closed, (3, 3), 0)\n",
        "\n",
        "# Optional: invert if text is white\n",
        "if np.mean(blurred) < 127:\n",
        "    blurred = cv2.bitwise_not(blurred)\n",
        "\n",
        "# Save for debugging\n",
        "cv2.imwrite(\"ocr_ready.png\", blurred)\n",
        "\n",
        "# Tesseract config\n",
        "config = (\n",
        "    r'--psm 7 --oem 3 '\n",
        "    r'-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '\n",
        "    r'-c load_system_dawg=0 -c load_freq_dawg=0'\n",
        ")\n",
        "\n",
        "# OCR\n",
        "text = pytesseract.image_to_string(blurred, config=config).strip().replace(\" \", \"\")\n",
        "print(\"OCR Result:\", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OCR Result: \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(\"license_plate_image.png\")\n",
        "\n",
        "# Rotate the image by 180 degrees\n",
        "img = cv2.rotate(img, cv2.ROTATE_180)\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Enhance contrast with CLAHE\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "gray = clahe.apply(gray)\n",
        "\n",
        "# Resize to improve OCR accuracy\n",
        "resized = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# Morph close to connect thin/broken lines\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "closed = cv2.morphologyEx(resized, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# Optional: slight blur to suppress tiny noise\n",
        "blurred = cv2.GaussianBlur(closed, (3, 3), 0)\n",
        "\n",
        "# Optional: invert if text is white\n",
        "if np.mean(blurred) < 127:\n",
        "    blurred = cv2.bitwise_not(blurred)\n",
        "\n",
        "# Save for debugging\n",
        "cv2.imwrite(\"ocr_ready.png\", blurred)\n",
        "\n",
        "# Tesseract config\n",
        "config = (\n",
        "    r'--psm 7 --oem 3 '\n",
        "    r'-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '\n",
        "    r'-c load_system_dawg=0 -c load_freq_dawg=0'\n",
        ")\n",
        "\n",
        "# OCR\n",
        "text = pytesseract.image_to_string(blurred, config=config).strip().replace(\" \", \"\")\n",
        "print(\"OCR Result:\", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\A'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\A'\n",
            "C:\\Users\\Akshat\\AppData\\Local\\Temp\\ipykernel_22252\\28749696.py:6: SyntaxWarning: invalid escape sequence '\\A'\n",
            "  cred = credentials.Certificate(\"D:\\Academics\\Semester VI\\ES 333 - Microprocessors and Embedded Systems\\PROJECT\\snippet.json\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entry logged for MH12AG7654 at 04:09:53 under ID 2\n"
          ]
        }
      ],
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize Firebase Admin SDK\n",
        "cred = credentials.Certificate(\"D:\\Academics\\Semester VI\\ES 333 - Microprocessors and Embedded Systems\\PROJECT\\snippet.json\")\n",
        "firebase_admin.initialize_app(cred, {\n",
        "    'databaseURL': 'https://anpr-bg-default-rtdb.asia-southeast1.firebasedatabase.app/'\n",
        "})\n",
        "\n",
        "def get_next_index(ref):\n",
        "    \"\"\"Get the next sequential integer key as a string.\"\"\"\n",
        "    existing_data = ref.get()\n",
        "    if not existing_data:\n",
        "        return \"1\"\n",
        "    \n",
        "    existing_keys = [int(key) for key in existing_data.keys() if key.isdigit()]\n",
        "    if not existing_keys:\n",
        "        return \"1\"\n",
        "    \n",
        "    return str(max(existing_keys) + 1)\n",
        "\n",
        "def add_vehicle_entry(vehicle_number):\n",
        "    \"\"\"Adds an outsider vehicle entry with a timestamp and plate number under a sequential key.\"\"\"\n",
        "    ref = db.reference(\"outsiders\")\n",
        "    now = datetime.now().strftime(\"%H:%M:%S\")  # Current time\n",
        "\n",
        "    next_index = get_next_index(ref)\n",
        "    \n",
        "    ref.child(next_index).set({\n",
        "        \"entry\": now,\n",
        "        \"plate\": vehicle_number\n",
        "    })\n",
        "\n",
        "    print(f\"Entry logged for {vehicle_number} at {now} under ID {next_index}\")\n",
        "\n",
        "# Get user input and log entry\n",
        "vehicle_number = \"MH12AG7654\"\n",
        "add_vehicle_entry(vehicle_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected license plate: \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(\"license_plate_image.png\")\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply thresholding to preprocess the image\n",
        "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "# Perform text extraction\n",
        "config = '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "text = pytesseract.image_to_string(thresh, config=config)\n",
        "\n",
        "# Clean up the text\n",
        "clean_text = ''.join(e for e in text if e.isalnum())\n",
        "\n",
        "print(f\"Detected license plate: {clean_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method 4 detected: MHA5XY2468\n",
            "\n",
            "Final detected license plate: MHA5XY2468\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(\"license_plate_image.jpg\")\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply multiple preprocessing techniques and try OCR on each\n",
        "results = []\n",
        "\n",
        "# 1. Basic thresholding\n",
        "_, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "results.append(thresh1)\n",
        "\n",
        "# 2. Adaptive thresholding\n",
        "thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "results.append(thresh2)\n",
        "\n",
        "# 3. Contrast enhancement\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "enhanced = clahe.apply(gray)\n",
        "_, thresh3 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "results.append(thresh3)\n",
        "\n",
        "# 4. Denoising + thresholding\n",
        "denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
        "_, thresh4 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "results.append(thresh4)\n",
        "\n",
        "# OCR configuration\n",
        "config = '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "\n",
        "# Try OCR on all preprocessed images\n",
        "all_texts = []\n",
        "for i, processed_img in enumerate(results):\n",
        "    # Add border to help Tesseract\n",
        "    processed_img = cv2.copyMakeBorder(processed_img, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=255)\n",
        "    \n",
        "    # Save intermediate results for debugging\n",
        "    cv2.imwrite(f\"processed_{i+1}.jpg\", processed_img)\n",
        "    \n",
        "    # Perform OCR\n",
        "    text = pytesseract.image_to_string(processed_img, config=config).strip()\n",
        "    clean_text = ''.join(e for e in text if e.isalnum())\n",
        "    \n",
        "    if clean_text:\n",
        "        all_texts.append(clean_text)\n",
        "        print(f\"Method {i+1} detected: {clean_text}\")\n",
        "\n",
        "# Choose the most common result or the first non-empty one\n",
        "if all_texts:\n",
        "    from collections import Counter\n",
        "    most_common = Counter(all_texts).most_common(1)[0][0]\n",
        "    print(f\"\\nFinal detected license plate: {most_common}\")\n",
        "else:\n",
        "    print(\"No license plate detected with any method\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
